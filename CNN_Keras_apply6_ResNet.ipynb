{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy import ndimage, misc\n",
    "from PIL import Image\n",
    "from IPython.display import Image, display\n",
    "from glob import glob\n",
    "from matplotlib.image import imread\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.utils import plot_model\n",
    "from keras.layers import *\n",
    "from keras.callbacks import *\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD, adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from keras.applications import *\n",
    "\n",
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By Augmentation, Accuracy 91.95% -> 93.77%\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "    height_shift_range=0.05,\\\n",
    "    width_shift_range=0.05, \\\n",
    "    shear_range = 5, \\\n",
    "    zoom_range = 0.05, \\\n",
    "    rotation_range = 3, \\\n",
    "    horizontal_flip = True, \\\n",
    "    vertical_flip = True, \\\n",
    "    channel_shift_range = 15, \\\n",
    "    samplewise_center = True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255, \\\n",
    "    samplewise_center = True)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255, \\\n",
    "    samplewise_center = True)\n",
    "\n",
    "batch_size = 32 # 16->64->32\n",
    "epochs = 200 # 50->100 ->200\n",
    "root_path = '/home/mywork/kijun_kwon/data_split1'\n",
    "train_path = root_path +'/train'\n",
    "val_path = root_path +'/val'\n",
    "test_path = root_path +'/test'\n",
    "path_list = [train_path, val_path, test_path]\n",
    "\n",
    "class_root='/home/mywork/kijun_kwon/data_split1/train'\n",
    "class_list = [ item for item in os.listdir(class_root) if os.path.isdir(os.path.join(class_root, item)) ]\n",
    "class_list.sort()\n",
    "\n",
    "sizesOfSet = [0, 0, 0] # size of training set, validation set, test set\n",
    "for p in range(len(path_list)) :\n",
    "    for i in range(len(class_list)):\n",
    "        sizesOfSet[p] += (len([name for name in os.listdir(path_list[p] + '/'+ class_list[i]) if os.path.isfile(os.path.join(path_list[p]+ '/'+ class_list[i], name))]))\n",
    "\n",
    "image_height = 224\n",
    "image_width = 224\n",
    "channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(include_top=True, weights = None, input_tensor=None, input_shape=(image_height,image_width,channels), pooling=None, classes=len(class_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1965 images belonging to 7 classes.\n",
      "Found 658 images belonging to 7 classes.\n",
      "Found 655 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        color_mode = \"rgb\",\n",
    "        target_size=(image_height, image_width),\n",
    "        batch_size = batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_path,\n",
    "        shuffle = False,\n",
    "        color_mode = \"rgb\",\n",
    "        target_size=(image_height, image_width),    \n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "        val_path,\n",
    "        color_mode = \"rgb\",\n",
    "        target_size=(image_height, image_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint(('./ResNet50.{epoch:02d}.hdf5'),\n",
    "                                   monitor='val_loss',\n",
    "                                   verbose=1,\n",
    "                                   save_best_only=True,\n",
    "                                   save_weights_only=True)\n",
    "\n",
    "reduce_learning_rate = ReduceLROnPlateau(monitor='val_loss', factor=0.3,\n",
    "                                         patience=10, verbose=1)\n",
    "\n",
    "callbacks = [model_checkpoint, reduce_learning_rate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "61/61 [==============================] - 38s 622ms/step - loss: 1.5550 - acc: 0.4978 - val_loss: 9.5475 - val_acc: 0.1375\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 9.54752, saving model to ./ResNet50.01.hdf5\n",
      "Epoch 2/200\n",
      "61/61 [==============================] - 30s 488ms/step - loss: 1.2031 - acc: 0.5831 - val_loss: 8.4333 - val_acc: 0.1814\n",
      "\n",
      "Epoch 00002: val_loss improved from 9.54752 to 8.43329, saving model to ./ResNet50.02.hdf5\n",
      "Epoch 3/200\n",
      "61/61 [==============================] - 32s 526ms/step - loss: 0.9890 - acc: 0.6559 - val_loss: 14.0760 - val_acc: 0.1043\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 8.43329\n",
      "Epoch 4/200\n",
      "61/61 [==============================] - 29s 473ms/step - loss: 0.8462 - acc: 0.7065 - val_loss: 9.1721 - val_acc: 0.1461\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 8.43329\n",
      "Epoch 5/200\n",
      "61/61 [==============================] - 38s 619ms/step - loss: 0.8008 - acc: 0.7253 - val_loss: 6.2413 - val_acc: 0.2167\n",
      "\n",
      "Epoch 00005: val_loss improved from 8.43329 to 6.24125, saving model to ./ResNet50.05.hdf5\n",
      "Epoch 6/200\n",
      "61/61 [==============================] - 30s 486ms/step - loss: 0.8127 - acc: 0.7332 - val_loss: 3.1277 - val_acc: 0.3419\n",
      "\n",
      "Epoch 00006: val_loss improved from 6.24125 to 3.12767, saving model to ./ResNet50.06.hdf5\n",
      "Epoch 7/200\n",
      "61/61 [==============================] - 28s 454ms/step - loss: 0.7022 - acc: 0.7552 - val_loss: 5.0331 - val_acc: 0.3756\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 3.12767\n",
      "Epoch 8/200\n",
      "61/61 [==============================] - 29s 474ms/step - loss: 0.7060 - acc: 0.7608 - val_loss: 2.6584 - val_acc: 0.3114\n",
      "\n",
      "Epoch 00008: val_loss improved from 3.12767 to 2.65845, saving model to ./ResNet50.08.hdf5\n",
      "Epoch 9/200\n",
      "61/61 [==============================] - 27s 437ms/step - loss: 0.6662 - acc: 0.7569 - val_loss: 2.7631 - val_acc: 0.3628\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.65845\n",
      "Epoch 10/200\n",
      "61/61 [==============================] - 26s 430ms/step - loss: 0.6253 - acc: 0.7792 - val_loss: 5.6976 - val_acc: 0.1027\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2.65845\n",
      "Epoch 11/200\n",
      "61/61 [==============================] - 25s 417ms/step - loss: 0.5311 - acc: 0.8043 - val_loss: 2.6354 - val_acc: 0.2793\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.65845 to 2.63538, saving model to ./ResNet50.11.hdf5\n",
      "Epoch 12/200\n",
      "61/61 [==============================] - 25s 411ms/step - loss: 0.5501 - acc: 0.8107 - val_loss: 2.1619 - val_acc: 0.6067\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.63538 to 2.16194, saving model to ./ResNet50.12.hdf5\n",
      "Epoch 13/200\n",
      "61/61 [==============================] - 24s 393ms/step - loss: 0.5854 - acc: 0.7967 - val_loss: 0.9310 - val_acc: 0.7127\n",
      "\n",
      "Epoch 00013: val_loss improved from 2.16194 to 0.93100, saving model to ./ResNet50.13.hdf5\n",
      "Epoch 14/200\n",
      "61/61 [==============================] - 26s 420ms/step - loss: 0.5299 - acc: 0.8136 - val_loss: 1.3520 - val_acc: 0.5570\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.93100\n",
      "Epoch 15/200\n",
      "61/61 [==============================] - 25s 415ms/step - loss: 0.5146 - acc: 0.8210 - val_loss: 1.2377 - val_acc: 0.5409\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.93100\n",
      "Epoch 16/200\n",
      "61/61 [==============================] - 26s 418ms/step - loss: 0.4550 - acc: 0.8412 - val_loss: 1.8277 - val_acc: 0.4671\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.93100\n",
      "Epoch 17/200\n",
      "61/61 [==============================] - 26s 419ms/step - loss: 0.4997 - acc: 0.8274 - val_loss: 5.7067 - val_acc: 0.2279\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.93100\n",
      "Epoch 18/200\n",
      "61/61 [==============================] - 26s 421ms/step - loss: 0.4893 - acc: 0.8395 - val_loss: 1.6590 - val_acc: 0.5698\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.93100\n",
      "Epoch 19/200\n",
      "61/61 [==============================] - 25s 416ms/step - loss: 0.4171 - acc: 0.8510 - val_loss: 2.9346 - val_acc: 0.5618\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.93100\n",
      "Epoch 20/200\n",
      "61/61 [==============================] - 26s 427ms/step - loss: 0.5100 - acc: 0.8326 - val_loss: 2.4448 - val_acc: 0.4141\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.93100\n",
      "Epoch 21/200\n",
      "61/61 [==============================] - 26s 431ms/step - loss: 0.3800 - acc: 0.8650 - val_loss: 1.7823 - val_acc: 0.4864\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.93100\n",
      "Epoch 22/200\n",
      "61/61 [==============================] - 26s 423ms/step - loss: 0.3755 - acc: 0.8637 - val_loss: 1.0960 - val_acc: 0.7453\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.93100\n",
      "Epoch 23/200\n",
      "61/61 [==============================] - 27s 443ms/step - loss: 0.3911 - acc: 0.8640 - val_loss: 0.7374 - val_acc: 0.8138\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.93100 to 0.73736, saving model to ./ResNet50.23.hdf5\n",
      "Epoch 24/200\n",
      "61/61 [==============================] - 26s 420ms/step - loss: 0.3438 - acc: 0.8796 - val_loss: 1.9215 - val_acc: 0.5024\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.73736\n",
      "Epoch 25/200\n",
      "61/61 [==============================] - 25s 416ms/step - loss: 0.3296 - acc: 0.8901 - val_loss: 0.5305 - val_acc: 0.8250\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.73736 to 0.53046, saving model to ./ResNet50.25.hdf5\n",
      "Epoch 26/200\n",
      "61/61 [==============================] - 26s 427ms/step - loss: 0.3751 - acc: 0.8750 - val_loss: 0.4589 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.53046 to 0.45892, saving model to ./ResNet50.26.hdf5\n",
      "Epoch 27/200\n",
      "61/61 [==============================] - 26s 418ms/step - loss: 0.3740 - acc: 0.8786 - val_loss: 2.5212 - val_acc: 0.4398\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.45892\n",
      "Epoch 28/200\n",
      "61/61 [==============================] - 26s 431ms/step - loss: 0.3321 - acc: 0.8832 - val_loss: 0.6135 - val_acc: 0.8266\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.45892\n",
      "Epoch 29/200\n",
      "61/61 [==============================] - 26s 425ms/step - loss: 0.3213 - acc: 0.8958 - val_loss: 1.2173 - val_acc: 0.6356\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.45892\n",
      "Epoch 30/200\n",
      "61/61 [==============================] - 26s 420ms/step - loss: 0.3203 - acc: 0.8971 - val_loss: 0.6722 - val_acc: 0.8266\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.45892\n",
      "Epoch 31/200\n",
      "61/61 [==============================] - 26s 423ms/step - loss: 0.2670 - acc: 0.9129 - val_loss: 0.3394 - val_acc: 0.8828\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.45892 to 0.33936, saving model to ./ResNet50.31.hdf5\n",
      "Epoch 32/200\n",
      "61/61 [==============================] - 25s 415ms/step - loss: 0.3123 - acc: 0.8953 - val_loss: 2.3473 - val_acc: 0.4559\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.33936\n",
      "Epoch 33/200\n",
      "61/61 [==============================] - 25s 407ms/step - loss: 0.3540 - acc: 0.8919 - val_loss: 0.4577 - val_acc: 0.8299\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.33936\n",
      "Epoch 34/200\n",
      "61/61 [==============================] - 25s 406ms/step - loss: 0.3298 - acc: 0.8861 - val_loss: 1.3592 - val_acc: 0.5939\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.33936\n",
      "Epoch 35/200\n",
      "61/61 [==============================] - 25s 407ms/step - loss: 0.2886 - acc: 0.9055 - val_loss: 2.0572 - val_acc: 0.5474\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.33936\n",
      "Epoch 36/200\n",
      "61/61 [==============================] - 25s 414ms/step - loss: 0.2867 - acc: 0.9062 - val_loss: 0.6736 - val_acc: 0.7897\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.33936\n",
      "Epoch 37/200\n",
      "61/61 [==============================] - 25s 406ms/step - loss: 0.2605 - acc: 0.9107 - val_loss: 1.9692 - val_acc: 0.4735\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.33936\n",
      "Epoch 38/200\n",
      "61/61 [==============================] - 26s 420ms/step - loss: 0.2182 - acc: 0.9275 - val_loss: 0.4630 - val_acc: 0.8587\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.33936\n",
      "Epoch 39/200\n",
      "61/61 [==============================] - 26s 419ms/step - loss: 0.2591 - acc: 0.9114 - val_loss: 0.8504 - val_acc: 0.7657\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.33936\n",
      "Epoch 40/200\n",
      "61/61 [==============================] - 26s 419ms/step - loss: 0.2350 - acc: 0.9147 - val_loss: 1.2095 - val_acc: 0.7159\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.33936\n",
      "Epoch 41/200\n",
      "61/61 [==============================] - 25s 417ms/step - loss: 0.2836 - acc: 0.9004 - val_loss: 5.1992 - val_acc: 0.2600\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.33936\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "Epoch 42/200\n",
      "61/61 [==============================] - 25s 410ms/step - loss: 0.2004 - acc: 0.9274 - val_loss: 0.3978 - val_acc: 0.8604\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.33936\n",
      "Epoch 43/200\n",
      "61/61 [==============================] - 26s 420ms/step - loss: 0.1573 - acc: 0.9472 - val_loss: 0.2088 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.33936 to 0.20876, saving model to ./ResNet50.43.hdf5\n",
      "Epoch 44/200\n",
      "61/61 [==============================] - 28s 452ms/step - loss: 0.1434 - acc: 0.9537 - val_loss: 0.2811 - val_acc: 0.9117\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.20876\n",
      "Epoch 45/200\n",
      "61/61 [==============================] - 26s 426ms/step - loss: 0.1365 - acc: 0.9529 - val_loss: 0.1632 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.20876 to 0.16320, saving model to ./ResNet50.45.hdf5\n",
      "Epoch 46/200\n",
      "61/61 [==============================] - 25s 407ms/step - loss: 0.1207 - acc: 0.9544 - val_loss: 0.2781 - val_acc: 0.9262\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.16320\n",
      "Epoch 47/200\n",
      "61/61 [==============================] - 25s 413ms/step - loss: 0.1277 - acc: 0.9585 - val_loss: 0.4481 - val_acc: 0.8892\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.16320\n",
      "Epoch 48/200\n",
      "61/61 [==============================] - 25s 416ms/step - loss: 0.1233 - acc: 0.9593 - val_loss: 0.3541 - val_acc: 0.8732\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.16320\n",
      "Epoch 49/200\n",
      "39/61 [==================>...........] - ETA: 7s - loss: 0.1042 - acc: 0.9648"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch = sizesOfSet[0] // batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_data=val_generator,\n",
    "            validation_steps= sizesOfSet[1] // batch_size,\n",
    "            callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Y_pred = model.predict_generator(test_generator, sizesOfSet[2] // batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('\\tConfusion Matrix')\n",
    "conf = confusion_matrix(test_generator.classes, y_pred)\n",
    "print(conf)\n",
    "print('\\n\\t\\t\\tClassification Report')\n",
    "report = classification_report(test_generator.classes, y_pred, target_names=class_list)\n",
    "report_dict = classification_report(test_generator.classes, y_pred, target_names=class_list, output_dict = True)\n",
    "print(report)\n",
    "print(\"\\n-- Evaluate --\")\n",
    "scores = model.evaluate_generator(test_generator)\n",
    "under = 1-report_dict['ok']['precision']\n",
    "over = 1-report_dict['ok']['recall']\n",
    "print(\"%s: %.2f\\t%s: %.2f%%\\n과검율: %.2f%%\\t 미검율: %.2f%%\"\n",
    "      %(model.metrics_names[0], scores[0], model.metrics_names[1], scores[1]*100,\n",
    "        over*100, under*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_truth = list()\n",
    "error_count = list()\n",
    "error_pred = list()\n",
    "count = 0\n",
    "for i in range(len(y_pred)):\n",
    "    if i>0 :\n",
    "        if test_generator.classes[i-1]!=test_generator.classes[i]:\n",
    "            count = 0\n",
    "    if(test_generator.classes[i]!=y_pred[i]):\n",
    "        error_truth += [test_generator.classes[i]]\n",
    "        error_count += [count]\n",
    "        error_pred += [y_pred[i]]\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "underImageList = list()\n",
    "for i in range(len(class_list)):\n",
    "    lgc_file = glob(test_path + '/' + class_list[i] + '/*.jpg')\n",
    "    for j in range(len(error_truth)):\n",
    "        if i==error_truth[j] :\n",
    "#             print('Truth: ')\n",
    "#             print(class_list[error_truth[j]])\n",
    "#             print('Predicted as: ')\n",
    "#             print(class_list[error_pred[j]])\n",
    "#             display(Image(filename=lgc_file[error_count[j]]) )\n",
    "            if error_pred[j]==2 :\n",
    "                underImageList.append(lgc_file[error_count[j]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "underImageList"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
